{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb848ea-3ae9-4ca5-948c-44a451ffee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be1fd20d-c6ac-46e2-94f5-33bad120fb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b1479d-e2e4-4833-a06e-7264a7b83bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c86aa1-c7c4-4308-aa40-82f76444d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ac1f0aa-89a4-4883-89c0-f43ec085a680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))   # alphabetically sorted list of unique set of letters (26)\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}  # creates a dict with mapping of index to each letter. eg {'a': 0, 'b':1 ...}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "155cf3f6-49d0-4379-be1a-599594905d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']   # a single '.' character to indicate start and end of a word\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]  # input\n",
    "        ix2 = stoi[ch2]  # input\n",
    "        ix3 = stoi[ch3]  # output\n",
    "        xs.append([ix1, ix2])  # here we're adding the integer denoting the letter into the array, not the letter itself. because you can't do math on characters ofc\n",
    "        ys.append(ix3)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "52168190-8046-44b4-a3b7-ad34ddebce9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  5],\n",
       "        [ 5, 13],\n",
       "        [13, 13],\n",
       "        [13,  1]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e84c3b9d-886d-4c4c-bc36-504a8afb3d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 13,  1,  0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "70a9b4b8-faa4-4b90-a9bb-4afaa07ab1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 1.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there's no function called two hot encoding so we have to do it manually\n",
    "\n",
    "xenc = torch.zeros((xs.shape[0], 27))   # xs.shape[0] gives us the number of pairs in xs  # we don't have a num_classes attribute here so we directly set it to 27\n",
    "\n",
    "for i, (ix1, ix2) in enumerate(xs):\n",
    "    xenc[i, ix1] = 1\n",
    "    xenc[i, ix2] = 1\n",
    "\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "41ceb447-234b-48b4-9df4-937defe4f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a function for two hot encoding so we can reuse it\n",
    "\n",
    "def two_hot(passed_xs, num_classes):\n",
    "    xenc = torch.zeros((passed_xs.shape[0], num_classes))   # xs.shape[0] gives us the number of pairs in xs  # we don't have a num_classes attribute here so we directly set it to 27\n",
    "    for i, (ix1, ix2) in enumerate(passed_xs):\n",
    "        xenc[i, ix1] = 1\n",
    "        xenc[i, ix2] = 1\n",
    "    return xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "697eae0f-406e-49c0-8f91-251caf89b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((27, 27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5482421d-d63d-4dc4-82ed-e726c1b10390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0397,  1.2457,  0.2901, -0.0420,  2.6841,  0.4386, -2.2036,  1.2215,\n",
       "         -0.5428,  1.4147,  0.8850,  1.0213, -0.7843, -0.4343,  0.8613,  3.4891,\n",
       "          2.0364, -3.0127,  2.3001, -0.6684,  1.9733,  0.3582, -0.4597, -1.4579,\n",
       "         -0.4983,  0.3709,  3.4052],\n",
       "        [ 0.6660,  2.5362,  0.9514,  1.3167,  3.3623,  0.2197, -0.6317,  0.5862,\n",
       "          0.9402,  0.0616,  0.1218,  1.3564, -1.1297,  0.0366, -1.0704, -0.2714,\n",
       "          1.2971, -2.1377,  2.5507, -1.3129,  0.7755, -0.6795,  0.3589, -2.1397,\n",
       "          1.1172, -1.5253,  0.2513],\n",
       "        [ 0.1936,  1.0532,  0.6339,  0.2579,  0.9641, -0.2485,  0.0248, -0.0304,\n",
       "          1.5622, -0.4485, -1.2345,  1.1220, -0.6738,  0.0379, -0.5588, -0.8271,\n",
       "          0.8225, -0.7510,  0.9278, -1.4849, -0.2129, -1.1860, -0.6609, -0.2335,\n",
       "          1.5447,  0.6006, -0.7091],\n",
       "        [-0.4765, -0.1667,  0.9371, -0.8146,  1.6917, -0.1974,  1.3342, -0.8326,\n",
       "          0.7117, -2.2553,  0.0178, -0.1036,  0.5427, -0.9269, -0.7909, -1.1747,\n",
       "          1.1550, -2.0773,  2.0502, -0.8885,  0.2455, -1.1320, -2.4009, -0.1179,\n",
       "          2.3479,  1.1417, -1.8737]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d87e3558-90bd-46b2-ad3c-431c46779ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "# probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "420129f3-ad6b-491a-9d2a-13f7f30e32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9687596-6cad-46e0-a174-9d7d701b6497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.2061, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -probs[torch.arange(4), ys].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "115fb896-3ae5-4d7d-abd6-556ffca1e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.grad = None  # set the gradient to zero at the start of each backward pass\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "670527a4-8390-4bab-bd07-987b265c2503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  196113\n"
     ]
    }
   ],
   "source": [
    "# now all at once, neatly put together\n",
    "\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']   # a single '.' character to indicate start and end of a word\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]  # input\n",
    "        ix2 = stoi[ch2]  # input\n",
    "        ix3 = stoi[ch3]  # output\n",
    "        trigram = (ch1, ch2, ch3)\n",
    "        xs.append([ix1, ix2])  # here we're adding the integer denoting the letter into the array, not the letter itself. because you can't do math on characters ofc\n",
    "        ys.append(ix3)\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.shape[0]\n",
    "print('number of examples: ', num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3b99fb39-2b59-4fa4-b47f-48482a88bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8abd4588-bd7e-4d00-aca6-e9a45e03446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual xencoding\n",
    "\n",
    "xenc = two_hot(xs, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6c642481-d72f-4906-a940-4b693631b005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4272801876068115\n",
      "2.4272778034210205\n",
      "2.4272749423980713\n",
      "2.427272319793701\n",
      "2.427269458770752\n",
      "2.427267074584961\n",
      "2.427264451980591\n",
      "2.4272618293762207\n",
      "2.4272592067718506\n",
      "2.4272565841674805\n",
      "2.4272544384002686\n",
      "2.4272515773773193\n",
      "2.427248954772949\n",
      "2.427246570587158\n",
      "2.427243947982788\n",
      "2.427241802215576\n",
      "2.427239179611206\n",
      "2.427236795425415\n",
      "2.427234411239624\n",
      "2.427231788635254\n",
      "2.427229642868042\n",
      "2.427227020263672\n",
      "2.427224636077881\n",
      "2.42722225189209\n",
      "2.427220106124878\n",
      "2.427217721939087\n",
      "2.427215576171875\n",
      "2.427212953567505\n",
      "2.427210807800293\n",
      "2.427208662033081\n",
      "2.42720627784729\n",
      "2.427203893661499\n",
      "2.427201747894287\n",
      "2.427199363708496\n",
      "2.4271974563598633\n",
      "2.4271950721740723\n",
      "2.4271931648254395\n",
      "2.4271907806396484\n",
      "2.4271886348724365\n",
      "2.4271864891052246\n",
      "2.4271841049194336\n",
      "2.427182197570801\n",
      "2.4271798133850098\n",
      "2.427177906036377\n",
      "2.427175760269165\n",
      "2.4271738529205322\n",
      "2.427171468734741\n",
      "2.4271695613861084\n",
      "2.4271674156188965\n",
      "2.4271655082702637\n",
      "2.427163600921631\n",
      "2.427161455154419\n",
      "2.427159309387207\n",
      "2.427157402038574\n",
      "2.4271554946899414\n",
      "2.4271535873413086\n",
      "2.4271512031555176\n",
      "2.4271492958068848\n",
      "2.427147388458252\n",
      "2.4271457195281982\n",
      "2.4271438121795654\n",
      "2.4271419048309326\n",
      "2.4271399974823\n",
      "2.427138090133667\n",
      "2.427136182785034\n",
      "2.4271345138549805\n",
      "2.4271323680877686\n",
      "2.4271304607391357\n",
      "2.427128553390503\n",
      "2.427126884460449\n",
      "2.4271249771118164\n",
      "2.4271230697631836\n",
      "2.42712140083313\n",
      "2.427119493484497\n",
      "2.4271178245544434\n",
      "2.4271159172058105\n",
      "2.427114248275757\n",
      "2.427112340927124\n",
      "2.4271106719970703\n",
      "2.4271092414855957\n",
      "2.427107334136963\n",
      "2.427105665206909\n",
      "2.4271037578582764\n",
      "2.4271018505096436\n",
      "2.427100419998169\n",
      "2.4270987510681152\n",
      "2.4270970821380615\n",
      "2.427095413208008\n",
      "2.427093505859375\n",
      "2.4270920753479004\n",
      "2.4270904064178467\n",
      "2.427088975906372\n",
      "2.4270870685577393\n",
      "2.4270853996276855\n",
      "2.427083969116211\n",
      "2.4270823001861572\n",
      "2.4270806312561035\n",
      "2.42707896232605\n",
      "2.427077293395996\n",
      "2.4270761013031006\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "\n",
    "    # forward pass\n",
    "    logits = xenc @ W  # predict log-counts\n",
    "    counts = logits.exp()  # equivalent to our initial N matrix containing the original frequencies\n",
    "    probs = counts / counts.sum(1, keepdim=True)  # probabilities for the next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()  # second term is called L2 regularization\n",
    "    print(loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None  # set gradient to zero\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += -0.1 * W.grad   # keep learning rate at 50 for 1st iteration, 1 for 2nd, 0.5 for 3rd, and the 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "81a17da3-9d32-4c2c-ac75-a26aed62d714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myona.\n",
      "iaemrailewlixan.\n",
      "isharekya.\n",
      "ljagkin.\n",
      "iuin.\n",
      "esicnaylula.\n",
      "ovyes.\n",
      "dyh.\n",
      "hmay.\n",
      "sem.\n"
     ]
    }
   ],
   "source": [
    "# finally sampling from our neural net\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    # for the first character\n",
    "    out = []\n",
    "    ix_one = 0   # we always start at index 0, where the start '.' character indicating the start of a word is\n",
    "    xenc = F.one_hot(torch.tensor([ix_one]), num_classes=27).float()\n",
    "    logits = xenc @ W  # predict log-counts\n",
    "    counts = logits.exp()  # equivalent to our initial N matrix containing the original frequencies\n",
    "    p = counts / counts.sum(1, keepdim=True)  # probabilities for next character\n",
    "    \n",
    "    ix_out = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix_out])\n",
    "    ix_two = ix_out\n",
    "    \n",
    "    while True:  \n",
    "\n",
    "        # for the characters after\n",
    "        xenc = two_hot(torch.tensor([[ix_one, ix_two]]), 27) # two hot encoding input to network\n",
    "        logits = xenc @ W  # predict log-counts\n",
    "        counts = logits.exp()  # equivalent to our initial N matrix containing the original frequencies\n",
    "        p = counts / counts.sum(1, keepdim=True)  # probabilities for next character\n",
    "\n",
    "        ix_two = ix_one\n",
    "        ix_one = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix_one])\n",
    "        \n",
    "        if ix_one == 0:\n",
    "            break\n",
    "            \n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7f0da5f0-e12e-4cca-aea4-865a89a8afe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered names have been successfully written to indian-names.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('Indian_Names.csv')  # Replace 'names.csv' with your actual file path\n",
    "\n",
    "# Extract the 'Name' column and convert all entries to strings, filtering out any NaN values\n",
    "names = df['Name'].dropna().astype(str).tolist()\n",
    "\n",
    "# Function to filter out names with unwanted characters\n",
    "def filter_name(name):\n",
    "    # Only allow a-z, A-Z, and period (.)\n",
    "    allowed_chars = re.compile(r'^[a-zA-Z.]+$')\n",
    "    return allowed_chars.match(name) is not None\n",
    "\n",
    "# Filter names\n",
    "filtered_names = [name for name in names if filter_name(name)]\n",
    "\n",
    "# Write filtered names to a text file\n",
    "with open('indian-names.txt', 'w') as f:\n",
    "    for name in filtered_names:\n",
    "        f.write(name + '\\n')\n",
    "\n",
    "print('Filtered names have been successfully written to indian-names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "09269dca-3442-4a85-b844-cf72c33363bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aabid',\n",
       " 'aabida',\n",
       " 'aachal',\n",
       " 'aadesh',\n",
       " 'aadil',\n",
       " 'aadish',\n",
       " 'aaditya',\n",
       " 'aaenab',\n",
       " 'aafreen',\n",
       " 'aafrin']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indian_words = open('indian-names.txt', 'r').read().splitlines()\n",
    "indian_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5a27b3c9-bd87-4847-a3b1-71513c59edfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  41095\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(indian_words))))   # alphabetically sorted list of unique set of letters (26)\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}  # creates a dict with mapping of index to each letter. eg {'a': 0, 'b':1 ...}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in indian_words:\n",
    "    chs = ['.'] + list(w) + ['.']   # a single '.' character to indicate start and end of a word\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]  # input\n",
    "        ix2 = stoi[ch2]  # input\n",
    "        ix3 = stoi[ch3]  # output\n",
    "        trigram = (ch1, ch2, ch3)\n",
    "        xs.append([ix1, ix2])  # here we're adding the integer denoting the letter into the array, not the letter itself. because you can't do math on characters ofc\n",
    "        ys.append(ix3)\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.shape[0]\n",
    "print('number of examples: ', num)\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)\n",
    "\n",
    "xenc = two_hot(xs, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "caa72b4e-58c3-4397-9a39-e6d10739d23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3373916149139404\n",
      "2.3373913764953613\n",
      "2.3373916149139404\n",
      "2.3373916149139404\n",
      "2.3373916149139404\n",
      "2.3373916149139404\n",
      "2.3373916149139404\n",
      "2.3373916149139404\n",
      "2.3373916149139404\n",
      "2.3373916149139404\n",
      "2.3373916149139404\n",
      "2.3373916149139404\n",
      "2.3373913764953613\n",
      "2.3373913764953613\n",
      "2.3373913764953613\n",
      "2.3373913764953613\n",
      "2.3373913764953613\n",
      "2.3373913764953613\n",
      "2.3373913764953613\n",
      "2.3373913764953613\n",
      "2.3373913764953613\n",
      "2.3373913764953613\n",
      "2.3373911380767822\n",
      "2.3373911380767822\n",
      "2.3373911380767822\n",
      "2.337390899658203\n",
      "2.3373911380767822\n",
      "2.3373911380767822\n",
      "2.3373911380767822\n",
      "2.3373911380767822\n",
      "2.3373911380767822\n",
      "2.3373911380767822\n",
      "2.3373911380767822\n",
      "2.3373911380767822\n",
      "2.3373911380767822\n",
      "2.3373911380767822\n",
      "2.3373911380767822\n",
      "2.3373911380767822\n",
      "2.3373911380767822\n",
      "2.337390899658203\n",
      "2.337390899658203\n",
      "2.337390899658203\n",
      "2.337390899658203\n",
      "2.337390899658203\n",
      "2.337390899658203\n",
      "2.337390899658203\n",
      "2.337390899658203\n",
      "2.337390899658203\n",
      "2.337390899658203\n",
      "2.3373911380767822\n",
      "2.337390899658203\n",
      "2.3373911380767822\n",
      "2.3373911380767822\n",
      "2.337390661239624\n",
      "2.337390661239624\n",
      "2.337390661239624\n",
      "2.337390661239624\n",
      "2.337390661239624\n",
      "2.337390661239624\n",
      "2.337390661239624\n",
      "2.337390661239624\n",
      "2.337390661239624\n",
      "2.337390661239624\n",
      "2.337390661239624\n",
      "2.337390422821045\n",
      "2.337390661239624\n",
      "2.337390422821045\n",
      "2.337390422821045\n",
      "2.337390422821045\n",
      "2.337390422821045\n",
      "2.337390422821045\n",
      "2.337390422821045\n",
      "2.337390422821045\n",
      "2.337390661239624\n",
      "2.337390661239624\n",
      "2.337390422821045\n",
      "2.337390422821045\n",
      "2.337390422821045\n",
      "2.337390422821045\n",
      "2.337390422821045\n",
      "2.337390422821045\n",
      "2.337390422821045\n",
      "2.337390184402466\n",
      "2.337390184402466\n",
      "2.337390184402466\n",
      "2.337390184402466\n",
      "2.337390184402466\n",
      "2.337390184402466\n",
      "2.337390184402466\n",
      "2.337390184402466\n",
      "2.3373897075653076\n",
      "2.3373897075653076\n",
      "2.3373897075653076\n",
      "2.3373897075653076\n",
      "2.3373897075653076\n",
      "2.3373897075653076\n",
      "2.3373899459838867\n",
      "2.3373899459838867\n",
      "2.3373899459838867\n",
      "2.3373899459838867\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "\n",
    "    # forward pass\n",
    "    logits = xenc @ W  # predict log-counts\n",
    "    counts = logits.exp()  # equivalent to our initial N matrix containing the original frequencies\n",
    "    probs = counts / counts.sum(1, keepdim=True)  # probabilities for the next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()  # second term is called L2 regularization\n",
    "    print(loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None  # set gradient to zero\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += -0.1 * W.grad   # keep learning rate at 50 for 1st iteration, 1 for 2nd, 0.5 for 3rd, and the 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "40f91e04-113c-414e-b622-b227e05164f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaft.\n",
      "rayaaprishpraokharalt.\n",
      "nuleat.\n",
      "arual.\n",
      "iandind.\n",
      "eaim.\n",
      "orajkaisha.\n",
      "aiatalzii.\n",
      "onovrishooolveeeraghwiaeshgalla.\n",
      "numlialmoopmrinranrishakrajnadt.\n"
     ]
    }
   ],
   "source": [
    "# finally sampling from our neural net\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    # for the first character\n",
    "    out = []\n",
    "    ix_one = 0   # we always start at index 0, where the start '.' character indicating the start of a word is\n",
    "    xenc = F.one_hot(torch.tensor([ix_one]), num_classes=27).float()\n",
    "    logits = xenc @ W  # predict log-counts\n",
    "    counts = logits.exp()  # equivalent to our initial N matrix containing the original frequencies\n",
    "    p = counts / counts.sum(1, keepdim=True)  # probabilities for next character\n",
    "    \n",
    "    ix_out = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix_out])\n",
    "    ix_two = ix_out\n",
    "    \n",
    "    while True:  \n",
    "\n",
    "        # for the characters after\n",
    "        xenc = two_hot(torch.tensor([[ix_one, ix_two]]), 27) # two hot encoding input to network\n",
    "        logits = xenc @ W  # predict log-counts\n",
    "        counts = logits.exp()  # equivalent to our initial N matrix containing the original frequencies\n",
    "        p = counts / counts.sum(1, keepdim=True)  # probabilities for next character\n",
    "\n",
    "        ix_two = ix_one\n",
    "        ix_one = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix_one])\n",
    "        \n",
    "        if ix_one == 0:\n",
    "            break\n",
    "            \n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
