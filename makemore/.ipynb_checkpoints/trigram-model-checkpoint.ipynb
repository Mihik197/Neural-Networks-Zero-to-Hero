{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecb848ea-3ae9-4ca5-948c-44a451ffee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be1fd20d-c6ac-46e2-94f5-33bad120fb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b1479d-e2e4-4833-a06e-7264a7b83bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c86aa1-c7c4-4308-aa40-82f76444d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac1f0aa-89a4-4883-89c0-f43ec085a680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))   # alphabetically sorted list of unique set of letters (26)\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}  # creates a dict with mapping of index to each letter. eg {'a': 0, 'b':1 ...}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "155cf3f6-49d0-4379-be1a-599594905d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']   # a single '.' character to indicate start and end of a word\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]  # input\n",
    "        ix2 = stoi[ch2]  # input\n",
    "        ix3 = stoi[ch3]  # output\n",
    "        xs.append([ix1, ix2])  # here we're adding the integer denoting the letter into the array, not the letter itself. because you can't do math on characters ofc\n",
    "        ys.append(ix3)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52168190-8046-44b4-a3b7-ad34ddebce9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  5],\n",
       "        [ 5, 13],\n",
       "        [13, 13],\n",
       "        [13,  1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e84c3b9d-886d-4c4c-bc36-504a8afb3d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 13,  1,  0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "70a9b4b8-faa4-4b90-a9bb-4afaa07ab1c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 1.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there's no function called two hot encoding so we have to do it manually\n",
    "\n",
    "xenc = torch.zeros((xs.shape[0], 27))   # xs.shape[0] gives us the number of pairs in xs  # we don't have a num_classes attribute here so we directly set it to 27\n",
    "\n",
    "for i, (ix1, ix2) in enumerate(xs):\n",
    "    xenc[i, ix1] = 1\n",
    "    xenc[i, ix2] = 1\n",
    "\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "41ceb447-234b-48b4-9df4-937defe4f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a function for two hot encoding so we can reuse it\n",
    "\n",
    "def two_hot(passed_xs, num_classes):\n",
    "    xenc = torch.zeros((passed_xs.shape[0], num_classes))   # xs.shape[0] gives us the number of pairs in xs  # we don't have a num_classes attribute here so we directly set it to 27\n",
    "    for i, (ix1, ix2) in enumerate(passed_xs):\n",
    "        xenc[i, ix1] = 1\n",
    "        xenc[i, ix2] = 1\n",
    "    return xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "697eae0f-406e-49c0-8f91-251caf89b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((27*2, 27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5482421d-d63d-4dc4-82ed-e726c1b10390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (196113x27 and 54x27)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m xenc \u001b[38;5;241m=\u001b[39m two_hot(xs, \u001b[38;5;241m27\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m xenc \u001b[38;5;241m@\u001b[39m W\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (196113x27 and 54x27)"
     ]
    }
   ],
   "source": [
    "xenc = two_hot(xs, 27)\n",
    "xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87e3558-90bd-46b2-ad3c-431c46779ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = (xenc @ W).view(27*2, 27)\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "420129f3-ad6b-491a-9d2a-13f7f30e32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9687596-6cad-46e0-a174-9d7d701b6497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.2061, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -probs[torch.arange(4), ys].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "115fb896-3ae5-4d7d-abd6-556ffca1e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.grad = None  # set the gradient to zero at the start of each backward pass\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "670527a4-8390-4bab-bd07-987b265c2503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  196113\n"
     ]
    }
   ],
   "source": [
    "# now all at once, neatly put together\n",
    "\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']   # a single '.' character to indicate start and end of a word\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]  # input\n",
    "        ix2 = stoi[ch2]  # input\n",
    "        ix3 = stoi[ch3]  # output\n",
    "        trigram = (ch1, ch2, ch3)\n",
    "        xs.append([ix1, ix2])  # here we're adding the integer denoting the letter into the array, not the letter itself. because you can't do math on characters ofc\n",
    "        ys.append(ix3)\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.shape[0]\n",
    "print('number of examples: ', num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3b99fb39-2b59-4fa4-b47f-48482a88bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27*2, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8abd4588-bd7e-4d00-aca6-e9a45e03446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual xencoding\n",
    "\n",
    "# xenc = two_hot(xs, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b9544a91-6a52-49aa-b3ce-85d7569fad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs).float()\n",
    "xenc = xenc.view(-1, 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6c642481-d72f-4906-a940-4b693631b005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.263436794281006\n",
      "2.2631397247314453\n",
      "2.262847900390625\n",
      "2.2625620365142822\n",
      "2.2622814178466797\n",
      "2.2620060443878174\n",
      "2.2617361545562744\n",
      "2.2614707946777344\n",
      "2.2612104415893555\n",
      "2.2609548568725586\n",
      "2.2607038021087646\n",
      "2.2604572772979736\n",
      "2.2602148056030273\n",
      "2.259977102279663\n",
      "2.2597432136535645\n",
      "2.2595136165618896\n",
      "2.2592875957489014\n",
      "2.259065628051758\n",
      "2.258847236633301\n",
      "2.2586326599121094\n",
      "2.2584216594696045\n",
      "2.258213996887207\n",
      "2.258009672164917\n",
      "2.2578089237213135\n",
      "2.2576112747192383\n",
      "2.2574169635772705\n",
      "2.257225751876831\n",
      "2.2570371627807617\n",
      "2.2568519115448\n",
      "2.256669282913208\n",
      "2.2564895153045654\n",
      "2.256312847137451\n",
      "2.256138563156128\n",
      "2.255966901779175\n",
      "2.255798101425171\n",
      "2.255631685256958\n",
      "2.255467653274536\n",
      "2.2553060054779053\n",
      "2.2551469802856445\n",
      "2.2549901008605957\n",
      "2.254835605621338\n",
      "2.254683017730713\n",
      "2.254533052444458\n",
      "2.254384994506836\n",
      "2.2542388439178467\n",
      "2.2540950775146484\n",
      "2.253953218460083\n",
      "2.2538132667541504\n",
      "2.2536754608154297\n",
      "2.2535393238067627\n",
      "2.2534048557281494\n",
      "2.253272771835327\n",
      "2.2531421184539795\n",
      "2.2530131340026855\n",
      "2.2528860569000244\n",
      "2.252760410308838\n",
      "2.2526369094848633\n",
      "2.252514600753784\n",
      "2.252393960952759\n",
      "2.252274751663208\n",
      "2.25215744972229\n",
      "2.2520413398742676\n",
      "2.251926898956299\n",
      "2.2518136501312256\n",
      "2.251702070236206\n",
      "2.251591682434082\n",
      "2.2514829635620117\n",
      "2.251375198364258\n",
      "2.2512691020965576\n",
      "2.251163959503174\n",
      "2.2510602474212646\n",
      "2.25095796585083\n",
      "2.250856876373291\n",
      "2.2507569789886475\n",
      "2.2506582736968994\n",
      "2.2505605220794678\n",
      "2.2504642009735107\n",
      "2.25036883354187\n",
      "2.250274658203125\n",
      "2.2501814365386963\n",
      "2.250089645385742\n",
      "2.2499983310699463\n",
      "2.249908447265625\n",
      "2.24981951713562\n",
      "2.2497315406799316\n",
      "2.2496445178985596\n",
      "2.249558448791504\n",
      "2.2494735717773438\n",
      "2.249389410018921\n",
      "2.2493064403533936\n",
      "2.2492239475250244\n",
      "2.24914288520813\n",
      "2.2490622997283936\n",
      "2.2489826679229736\n",
      "2.24890398979187\n",
      "2.248826026916504\n",
      "2.248749017715454\n",
      "2.2486727237701416\n",
      "2.2485973834991455\n",
      "2.2485227584838867\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    logits = xenc @ W  # This will result in shape (196113, 27*27)    \n",
    "    counts = logits.exp()  # equivalent to our initial N matrix containing the original frequencies\n",
    "    probs = counts / counts.sum(1, keepdim=True)  # probabilities for the next character\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None  # set gradient to zero\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "81a17da3-9d32-4c2c-ac75-a26aed62d714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ajxpyan\n",
      "lettenerol\n",
      "oalyeostys\n",
      "zoret\n",
      "aub\n",
      "ylligganvermin\n",
      "alichsallimah\n",
      "on\n",
      "ary\n",
      "amilae\n"
     ]
    }
   ],
   "source": [
    "# finally sampling from our neural net\n",
    "import torch.nn.functional as F\n",
    "\n",
    "for _ in range(10):\n",
    "        out = []\n",
    "        ix_one = 0  # start character\n",
    "        ix_two = 0  # second start character (could also be 0)\n",
    "        \n",
    "        while True:\n",
    "            # One-hot encode the input\n",
    "            xenc = F.one_hot(torch.tensor([ix_one, ix_two]), num_classes=27).float()\n",
    "            xenc = xenc.view(1, -1)  # Reshape to (1, 54)\n",
    "            \n",
    "            # Get logits and probabilities\n",
    "            logits = xenc @ W\n",
    "            counts = logits.exp()\n",
    "            probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "            \n",
    "            # Sample next character\n",
    "            ix_next = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "            \n",
    "            if ix_next == 0:  # End of word\n",
    "                break\n",
    "            \n",
    "            out.append(itos[ix_next])\n",
    "            \n",
    "            # Update context\n",
    "            ix_one, ix_two = ix_two, ix_next\n",
    "        \n",
    "        print(''.join(out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7f0da5f0-e12e-4cca-aea4-865a89a8afe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered names have been successfully written to indian-names.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('Indian_Names.csv')\n",
    "\n",
    "# extract the 'Name' column and convert all entries to strings, filtering out any NaN values\n",
    "names = df['Name'].dropna().astype(str).tolist()\n",
    "\n",
    "# filter out names with unwanted characters\n",
    "def filter_name(name):\n",
    "    # only allow a-z, A-Z, and '.'\n",
    "    allowed_chars = re.compile(r'^[a-zA-Z.]+$')\n",
    "    return allowed_chars.match(name) is not None\n",
    "\n",
    "filtered_names = [name for name in names if filter_name(name)]\n",
    "\n",
    "with open('indian-names.txt', 'w') as f:\n",
    "    for name in filtered_names:\n",
    "        f.write(name + '\\n')\n",
    "\n",
    "print('Filtered names have been successfully written to indian-names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "09269dca-3442-4a85-b844-cf72c33363bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aabid',\n",
       " 'aabida',\n",
       " 'aachal',\n",
       " 'aadesh',\n",
       " 'aadil',\n",
       " 'aadish',\n",
       " 'aaditya',\n",
       " 'aaenab',\n",
       " 'aafreen',\n",
       " 'aafrin']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indian_words = open('indian-names.txt', 'r').read().splitlines()\n",
    "indian_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5a27b3c9-bd87-4847-a3b1-71513c59edfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  41095\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(indian_words))))   # alphabetically sorted list of unique set of letters (26)\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}  # creates a dict with mapping of index to each letter. eg {'a': 0, 'b':1 ...}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in indian_words:\n",
    "    chs = ['.'] + list(w) + ['.']   # a single '.' character to indicate start and end of a word\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]  # input\n",
    "        ix2 = stoi[ch2]  # input\n",
    "        ix3 = stoi[ch3]  # output\n",
    "        trigram = (ch1, ch2, ch3)\n",
    "        xs.append([ix1, ix2])  # here we're adding the integer denoting the letter into the array, not the letter itself. because you can't do math on characters ofc\n",
    "        ys.append(ix3)\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.shape[0]\n",
    "print('number of examples: ', num)\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27*2, 27), generator=g, requires_grad=True)\n",
    "\n",
    "xenc = F.one_hot(xs).float()\n",
    "xenc = xenc.view(-1, 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "caa72b4e-58c3-4397-9a39-e6d10739d23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.242604732513428\n",
      "3.2509896755218506\n",
      "2.9397175312042236\n",
      "2.776549816131592\n",
      "2.66982364654541\n",
      "2.595540761947632\n",
      "2.537872552871704\n",
      "2.4938223361968994\n",
      "2.456779718399048\n",
      "2.4280192852020264\n",
      "2.4022836685180664\n",
      "2.3828089237213135\n",
      "2.3638851642608643\n",
      "2.350182294845581\n",
      "2.3353281021118164\n",
      "2.325273036956787\n",
      "2.3130064010620117\n",
      "2.305455207824707\n",
      "2.2950046062469482\n",
      "2.2892937660217285\n",
      "2.2801990509033203\n",
      "2.275892734527588\n",
      "2.2678427696228027\n",
      "2.264629602432251\n",
      "2.257399797439575\n",
      "2.25504994392395\n",
      "2.248471975326538\n",
      "2.2468113899230957\n",
      "2.2407572269439697\n",
      "2.2396531105041504\n",
      "2.234025478363037\n",
      "2.2333741188049316\n",
      "2.2280991077423096\n",
      "2.2278192043304443\n",
      "2.222838878631592\n",
      "2.2228665351867676\n",
      "2.2181358337402344\n",
      "2.218421220779419\n",
      "2.213904857635498\n",
      "2.2144064903259277\n",
      "2.210076093673706\n",
      "2.2107625007629395\n",
      "2.206594228744507\n",
      "2.2074384689331055\n",
      "2.203413486480713\n",
      "2.2043938636779785\n",
      "2.200495719909668\n",
      "2.2015950679779053\n",
      "2.197809934616089\n",
      "2.1990129947662354\n",
      "2.195329189300537\n",
      "2.1966235637664795\n",
      "2.193031072616577\n",
      "2.194406747817993\n",
      "2.1908960342407227\n",
      "2.1923439502716064\n",
      "2.188908338546753\n",
      "2.190420627593994\n",
      "2.187052011489868\n",
      "2.1886227130889893\n",
      "2.1853160858154297\n",
      "2.186938524246216\n",
      "2.183688163757324\n",
      "2.1853578090667725\n",
      "2.182159185409546\n",
      "2.1838719844818115\n",
      "2.180720090866089\n",
      "2.182471990585327\n",
      "2.179363250732422\n",
      "2.1811509132385254\n",
      "2.1780824661254883\n",
      "2.1799027919769287\n",
      "2.1768710613250732\n",
      "2.1787211894989014\n",
      "2.1757235527038574\n",
      "2.1776013374328613\n",
      "2.174635171890259\n",
      "2.1765384674072266\n",
      "2.1736013889312744\n",
      "2.175528049468994\n",
      "2.1726181507110596\n",
      "2.1745665073394775\n",
      "2.171682357788086\n",
      "2.1736505031585693\n",
      "2.170789957046509\n",
      "2.172776937484741\n",
      "2.169938087463379\n",
      "2.1719424724578857\n",
      "2.1691246032714844\n",
      "2.171144962310791\n",
      "2.168346405029297\n",
      "2.170381784439087\n",
      "2.1676018238067627\n",
      "2.1696510314941406\n",
      "2.1668879985809326\n",
      "2.168950319290161\n",
      "2.166203737258911\n",
      "2.168278217315674\n",
      "2.1655466556549072\n",
      "2.167632579803467\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    logits = xenc @ W  # This will result in shape (196113, 27*27)    \n",
    "    counts = logits.exp()  # equivalent to our initial N matrix containing the original frequencies\n",
    "    probs = counts / counts.sum(1, keepdim=True)  # probabilities for the next character\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None  # set gradient to zero\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "40f91e04-113c-414e-b622-b227e05164f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "arajabybadhikami\n",
      "arbhukestyash\n",
      "oo\n",
      "kaddi\n",
      "azamai\n",
      "nohita\n",
      "arveennahanatana\n",
      "am\n",
      "ansav\n"
     ]
    }
   ],
   "source": [
    "# finally sampling from our neural net\n",
    "import torch.nn.functional as F\n",
    "\n",
    "for _ in range(10):\n",
    "        out = []\n",
    "        ix_one = 0  # start character\n",
    "        ix_two = 0  # second start character (could also be 0)\n",
    "        \n",
    "        while True:\n",
    "            # One-hot encode the input\n",
    "            xenc = F.one_hot(torch.tensor([ix_one, ix_two]), num_classes=27).float()\n",
    "            xenc = xenc.view(1, -1)  # Reshape to (1, 54)\n",
    "            \n",
    "            # Get logits and probabilities\n",
    "            logits = xenc @ W\n",
    "            counts = logits.exp()\n",
    "            probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "            \n",
    "            # Sample next character\n",
    "            ix_next = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "            \n",
    "            if ix_next == 0:  # End of word\n",
    "                break\n",
    "            \n",
    "            out.append(itos[ix_next])\n",
    "            \n",
    "            # Update context\n",
    "            ix_one, ix_two = ix_two, ix_next\n",
    "        \n",
    "        print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
